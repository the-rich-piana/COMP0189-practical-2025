{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdanny/COMP0189-practical/blob/main/Week-06/deepglobe_land_cover_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_IlD1eeQItn",
        "papermill": {
          "duration": 0.024489,
          "end_time": "2020-11-11T04:19:40.496749",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.472260",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "\n",
        "# COMP0189: Applied Artificial Intelligence\n",
        "## Week 5 (Deep Learning - image segmentation)\n",
        "\n",
        "In this notebook we use [Unet](https://arxiv.org/abs/1505.04597) for Land Cover Classfication from Satellite Imagery using [DeepGlobe Land Cover Classification Dataset](https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq2w-_Gb1zTm"
      },
      "source": [
        "**Land cover classification** involves analysing satellite images and segmenting them into regions based on their land cover type. These types include urban areas, forests, water bodies, and more. Segmentation **assigns a class label to each pixel**, creating detailed, colour-coded maps of land use.\n",
        "\n",
        "For example:\n",
        "- Pixels representing urban areas are assigned the RGB value (0, 255, 255).\n",
        "- Pixels representing water are assigned the RGB value (0, 0, 255).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQj6Y2k810qI"
      },
      "source": [
        "After this week you will be able to ...\n",
        "\n",
        "- Train U-Net models in PyTorch.\n",
        "- Implement Dice loss and BCE-Dice loss.\n",
        "- Visualize the prediction output on some of the test images using the trained U-Net.\n",
        "- Learn how data augmentation affects model training.\n",
        "- Compute the area of one class on the test set ground truth, the same class on the predicted masks on the same test set, and compute the difference between the two to see the error of your predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfbTqV1tQIto",
        "papermill": {
          "duration": 0.022878,
          "end_time": "2020-11-11T04:19:40.542961",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.520083",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Libraries üìö‚¨á"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZZjQKj93uQA",
        "outputId": "566b314e-2638-46ab-dedd-c75bfb1de5bf"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch==0.2.0\n",
        "!pip install opencv-python\n",
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-11-11T04:19:40.598993Z",
          "iopub.status.busy": "2020-11-11T04:19:40.598327Z",
          "iopub.status.idle": "2020-11-11T04:19:43.727682Z",
          "shell.execute_reply": "2020-11-11T04:19:43.726567Z"
        },
        "id": "Cd_Q_EbIQItp",
        "papermill": {
          "duration": 3.161749,
          "end_time": "2020-11-11T04:19:43.727814",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.566065",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:19:43.781230Z",
          "iopub.status.busy": "2020-11-11T04:19:43.780452Z",
          "iopub.status.idle": "2020-11-11T04:20:00.661333Z",
          "shell.execute_reply": "2020-11-11T04:20:00.660741Z"
        },
        "id": "pB2TsGb-QItq",
        "papermill": {
          "duration": 16.909556,
          "end_time": "2020-11-11T04:20:00.661450",
          "exception": false,
          "start_time": "2020-11-11T04:19:43.751894",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqGHSsB4om4b",
        "outputId": "cafba08e-028a-4b03-941d-c49ea737e803"
      },
      "outputs": [],
      "source": [
        "# Getting dataset's metadata\n",
        "! wget https://raw.githubusercontent.com/kimdanny/COMP0189-practical/main/data/class_dict.csv\n",
        "! wget https://raw.githubusercontent.com/kimdanny/COMP0189-practical/main/data/metadata.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeRyCVvTm6ZM",
        "outputId": "e2627f3a-34f5-4d4b-bafc-bfc79ad3e821"
      },
      "outputs": [],
      "source": [
        "# Downloading dataset\n",
        "! wget https://competitions.codalab.org/my/datasets/download/b6def20d-34c5-4871-8d9d-d97075179ea0 -O land-train.zip\n",
        "! wget https://competitions.codalab.org/my/datasets/download/dfb325b3-4e9c-43c0-93b3-036eec5fa773 -O land_valid_sat.zip\n",
        "! wget https://competitions.codalab.org/my/datasets/download/61ac1b46-9bd3-4694-810f-ffd08a7f832a -O land_test_sat.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cFThp64obH4"
      },
      "outputs": [],
      "source": [
        "! unzip -qq land-train.zip\n",
        "! mv land-train train\n",
        "! unzip -qq land_valid_sat.zip -d valid\n",
        "! unzip -qq land_test_sat.zip -d test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JuDPChTQItq",
        "papermill": {
          "duration": 0.023301,
          "end_time": "2020-11-11T04:20:00.708750",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.685449",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Read Data & Create train / valid splits üìÅ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ4cH84Ey8y-"
      },
      "source": [
        "We previously downloaded the datasets metadata files.\n",
        "\n",
        "`metadata.csv` reports the image IDs, image paths, which split they belong to, and the path to the segmentation mask (label).  \n",
        "`class_dict.csv` reports the RGB colour code for each of the 7 possible classes in the segmentation masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2YU1w3lkzRHy",
        "outputId": "47faacdf-2467-4c64-8a3c-ebc6b490025c"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/'\n",
        "\n",
        "# Load metadata into df\n",
        "metadata_df = pd.read_csv(os.path.join(DATA_DIR, 'metadata.csv'))\n",
        "\n",
        "metadata_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p0pZc1SWzRpD",
        "outputId": "7500c5a9-c611-4bdc-b5d4-b0a7cea2e6bf"
      },
      "outputs": [],
      "source": [
        "# Load class info into df\n",
        "class_dict_df = pd.read_csv(os.path.join(DATA_DIR, 'class_dict.csv'))\n",
        "\n",
        "class_dict_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0Ru8Ru2ztKI"
      },
      "source": [
        "Use the metadata to create your data splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.768015Z",
          "iopub.status.busy": "2020-11-11T04:20:00.767115Z",
          "iopub.status.idle": "2020-11-11T04:20:00.796084Z",
          "shell.execute_reply": "2020-11-11T04:20:00.796568Z"
        },
        "id": "ogMMvJUBQItr",
        "outputId": "8c837c66-e8ea-469a-da32-58dc2d3208bf",
        "papermill": {
          "duration": 0.064492,
          "end_time": "2020-11-11T04:20:00.796691",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.732199",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get train set & select relevant columns\n",
        "metadata_df = metadata_df[metadata_df['split']=='train']\n",
        "metadata_df = metadata_df[['image_id', 'sat_image_path', 'mask_path']]\n",
        "\n",
        "# Update paths\n",
        "metadata_df['sat_image_path'] = metadata_df['sat_image_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "metadata_df['mask_path'] = metadata_df['mask_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "\n",
        "# Shuffle dataframe\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Perform 80/20 split for train / test\n",
        "test_df = metadata_df.sample(frac=0.2, random_state=42)\n",
        "train_df = metadata_df.drop(test_df.index)\n",
        "\n",
        "# Perform 90/10 split for train / val\n",
        "valid_df = train_df.sample(frac=0.1, random_state=42)\n",
        "train_df = train_df.drop(valid_df.index)\n",
        "\n",
        "# Check number of samples\n",
        "print('Train / test / val samples:')\n",
        "print(len(train_df), '/', len(test_df), '/', len(valid_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQZ0TSc15vE6"
      },
      "source": [
        "Extract label information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.852070Z",
          "iopub.status.busy": "2020-11-11T04:20:00.851216Z",
          "iopub.status.idle": "2020-11-11T04:20:00.860652Z",
          "shell.execute_reply": "2020-11-11T04:20:00.859981Z"
        },
        "id": "PrS7OOwqQIts",
        "outputId": "e951a783-0188-44c6-c509-d4964d3f77d2",
        "papermill": {
          "duration": 0.03956,
          "end_time": "2020-11-11T04:20:00.860779",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.821219",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get class names\n",
        "class_names = class_dict_df['name'].tolist()\n",
        "# Get class RGB values\n",
        "class_rgb_values = class_dict_df[['r','g','b']].values.tolist()\n",
        "\n",
        "print('All dataset classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_eVnHo2QIts",
        "papermill": {
          "duration": 0.024557,
          "end_time": "2020-11-11T04:20:00.910401",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.885844",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Shortlist specific classes to segment "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.966519Z",
          "iopub.status.busy": "2020-11-11T04:20:00.965617Z",
          "iopub.status.idle": "2020-11-11T04:20:00.970796Z",
          "shell.execute_reply": "2020-11-11T04:20:00.970160Z"
        },
        "id": "K55PxIauQItt",
        "outputId": "e63f51e2-6d49-4ea9-93e5-986a24ed7b94",
        "papermill": {
          "duration": 0.036145,
          "end_time": "2020-11-11T04:20:00.970921",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.934776",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Useful to shortlist specific classes in datasets with large number of classes\n",
        "select_classes = ['urban_land', 'agriculture_land', 'rangeland', 'forest_land', 'water', 'barren_land', 'unknown']\n",
        "\n",
        "# Get RGB values of required classes\n",
        "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
        "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n",
        "\n",
        "print('Selected classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdGCpfjsQItt",
        "papermill": {
          "duration": 0.024734,
          "end_time": "2020-11-11T04:20:01.021071",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.996337",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Helper functions for viz. & one-hot encoding/decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.080389Z",
          "iopub.status.busy": "2020-11-11T04:20:01.079533Z",
          "iopub.status.idle": "2020-11-11T04:20:01.088228Z",
          "shell.execute_reply": "2020-11-11T04:20:01.087750Z"
        },
        "id": "59bU68D0QItt",
        "papermill": {
          "duration": 0.042035,
          "end_time": "2020-11-11T04:20:01.088327",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.046292",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"\n",
        "    Plot images in one row\n",
        "    \"\"\"\n",
        "    n_images = len(images)\n",
        "    plt.figure(figsize=(20,8))\n",
        "    for idx, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n_images, idx + 1)\n",
        "        plt.xticks([]);\n",
        "        plt.yticks([])\n",
        "        # get title from the parameter names\n",
        "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# Perform one hot encoding on label\n",
        "def one_hot_encode(label, label_values):\n",
        "    \"\"\"\n",
        "    Convert a segmentation image label array to one-hot format\n",
        "    by replacing each pixel value with a vector of length num_classes\n",
        "    # Arguments\n",
        "        label: The 2D array segmentation image label\n",
        "        label_values\n",
        "\n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of num_classes\n",
        "    \"\"\"\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(label, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)\n",
        "\n",
        "    return semantic_map\n",
        "\n",
        "# Perform reverse one-hot-encoding on labels / preds\n",
        "def reverse_one_hot(image):\n",
        "    \"\"\"\n",
        "    Transform a 2D array in one-hot format (depth is num_classes),\n",
        "    to a 2D array with only 1 channel, where each pixel value is\n",
        "    the classified class key.\n",
        "    # Arguments\n",
        "        image: The one-hot format image\n",
        "\n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of 1, where each pixel value is the classified\n",
        "        class key.\n",
        "    \"\"\"\n",
        "    x = np.argmax(image, axis = -1)\n",
        "    return x\n",
        "\n",
        "# Perform colour coding on the reverse-one-hot outputs\n",
        "def colour_code_segmentation(image, label_values):\n",
        "    \"\"\"\n",
        "    Given a 1-channel array of class keys, colour code the segmentation results.\n",
        "    # Arguments\n",
        "        image: single channel array where each value represents the class key.\n",
        "        label_values\n",
        "\n",
        "    # Returns\n",
        "        Colour coded image for segmentation visualization\n",
        "    \"\"\"\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[image.astype(int)]\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "714IWFiotSka"
      },
      "source": [
        "## Custom Dataset class\n",
        "Pytorch has utilities that help us create well-structured datsets, which is important for computer vision tasks.\n",
        "\n",
        "This class inherits from `torch.utils.data.Dataset` and allows us to put together a dataset class that handles:\n",
        "- reading the satellite images and their corresponding segmentation masks\n",
        "- preprocessing such as one-hot encoding the segmentation masks\n",
        "- any desired operations on the data, such as augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.142187Z",
          "iopub.status.busy": "2020-11-11T04:20:01.141334Z",
          "iopub.status.idle": "2020-11-11T04:20:01.153771Z",
          "shell.execute_reply": "2020-11-11T04:20:01.154347Z"
        },
        "id": "N2Zf_hGOQItu",
        "papermill": {
          "duration": 0.041149,
          "end_time": "2020-11-11T04:20:01.154457",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.113308",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LandCoverDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    \"\"\"DeepGlobe Land Cover Classification Challenge Dataset. Read images, apply augmentation and preprocessing transformations.\n",
        "\n",
        "    Args:\n",
        "        df (str): DataFrame containing images / labels paths\n",
        "        class_rgb_values (list): RGB values of select classes to extract from segmentation mask\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline\n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing\n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            df,\n",
        "            class_rgb_values=None,\n",
        "            augmentation=None,\n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.image_paths = df['sat_image_path'].tolist()\n",
        "        self.mask_paths = df['mask_path'].tolist()\n",
        "\n",
        "        self.class_rgb_values = class_rgb_values\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        # read images and masks\n",
        "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # one-hot-encode the mask\n",
        "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
        "\n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        # return length of\n",
        "        return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ld70i2QItv",
        "papermill": {
          "duration": 0.0248,
          "end_time": "2020-11-11T04:20:01.204614",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.179814",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Visualize Sample Image and Mask üìà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.262566Z",
          "iopub.status.busy": "2020-11-11T04:20:01.261449Z",
          "iopub.status.idle": "2020-11-11T04:20:04.972786Z",
          "shell.execute_reply": "2020-11-11T04:20:04.972272Z"
        },
        "id": "EBC4RuDuQItv",
        "outputId": "cc4c5acd-6479-4958-c21c-2f9037344e7b",
        "papermill": {
          "duration": 3.743046,
          "end_time": "2020-11-11T04:20:04.972888",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.229842",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Instantiate the dataset\n",
        "dataset = LandCoverDataset(train_df, class_rgb_values=select_class_rgb_values)\n",
        "\n",
        "# Sample a random image to visualise\n",
        "random_idx = random.randint(0, len(dataset)-1)\n",
        "image, mask = dataset[random_idx]\n",
        "\n",
        "# Use helper function defined earlier to inspect image\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13lJ1tyTQItw",
        "papermill": {
          "duration": 0.031599,
          "end_time": "2020-11-11T04:20:05.037746",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.006147",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Defining Augmentation and preprocessing pipeline for data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:05.112791Z",
          "iopub.status.busy": "2020-11-11T04:20:05.111981Z",
          "iopub.status.idle": "2020-11-11T04:20:05.115075Z",
          "shell.execute_reply": "2020-11-11T04:20:05.114478Z"
        },
        "id": "VQQlWcOtQItw",
        "papermill": {
          "duration": 0.045522,
          "end_time": "2020-11-11T04:20:05.115181",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.069659",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "        album.RandomCrop(height=1024, width=1024, always_apply=True),\n",
        "        album.HorizontalFlip(p=0.5),\n",
        "        album.VerticalFlip(p=0.5),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    train_transform = [\n",
        "        album.CenterCrop(height=1024, width=1024, always_apply=True),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_training_no_augmentation():\n",
        "    train_transform = [\n",
        "        album.CenterCrop(height=1024, width=1024, always_apply=True),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn=None):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    Args:\n",
        "        preprocessing_fn (callable): data normalization function\n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \"\"\"\n",
        "    _transform = []\n",
        "    if preprocessing_fn:\n",
        "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
        "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
        "\n",
        "    return album.Compose(_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhkhbBjgQItx",
        "papermill": {
          "duration": 0.03172,
          "end_time": "2020-11-11T04:20:05.179602",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.147882",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Visualize Augmented Images & Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:05.250381Z",
          "iopub.status.busy": "2020-11-11T04:20:05.249704Z",
          "iopub.status.idle": "2020-11-11T04:20:11.456620Z",
          "shell.execute_reply": "2020-11-11T04:20:11.457108Z"
        },
        "id": "eiKMEI5DQIty",
        "outputId": "62021678-5b32-43b9-c605-3c6942861265",
        "papermill": {
          "duration": 6.245534,
          "end_time": "2020-11-11T04:20:11.457241",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.211707",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "augmented_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "image, mask = augmented_dataset[random_idx]\n",
        "visualize(\n",
        "        original_image = image,\n",
        "        ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "        one_hot_encoded_mask = reverse_one_hot(mask))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEU8DKdFQIty",
        "papermill": {
          "duration": 0.05496,
          "end_time": "2020-11-11T04:20:11.565134",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.510174",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training Unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wWLNIJdQItz",
        "papermill": {
          "duration": 0.052843,
          "end_time": "2020-11-11T04:20:11.772393",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.719550",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:11.881284Z",
          "iopub.status.busy": "2020-11-11T04:20:11.880373Z",
          "iopub.status.idle": "2020-11-11T04:20:17.009902Z",
          "shell.execute_reply": "2020-11-11T04:20:17.009318Z"
        },
        "id": "a3ZHSlQyQItz",
        "outputId": "019a10dc-408b-459d-d442-6bea654a1a43",
        "papermill": {
          "duration": 5.187035,
          "end_time": "2020-11-11T04:20:17.010064",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.823029",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "ENCODER = 'resnet50'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = select_classes\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "\n",
        "\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights=ENCODER_WEIGHTS,     # use `imagenet` pre-trained weights for encoder initialization\n",
        "    classes=len(CLASSES),\n",
        "    activation=ACTIVATION,# model output channels (number of classes in your dataset)\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NKfm2i9QIt0",
        "papermill": {
          "duration": 0.050739,
          "end_time": "2020-11-11T04:20:17.327158",
          "exception": false,
          "start_time": "2020-11-11T04:20:17.276419",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Task 1: Diceloss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndRpE6rV_Gy0"
      },
      "source": [
        "Implement the 1-dice loss\n",
        "(https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3W7EY0PNiwi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, activation='sigmoid'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        pr (torch.Tensor): Predicted tensor (logits or probabilities)\n",
        "        gt (torch.Tensor): Ground truth tensor (binary mask)\n",
        "        beta (float): Weight for precision-recall balance\n",
        "        eps (float): Small epsilon for numerical stability\n",
        "        threshold (float or None): Threshold for binarization (if needed)\n",
        "        activation (str): Activation function ('sigmoid' or 'softmax2d')\n",
        "    Returns:\n",
        "        float: Dice coefficient (F-score)\n",
        "    \"\"\"\n",
        "\n",
        "    if activation is None or activation == \"none\":\n",
        "        activation_fn = lambda x: x  # No activation applied\n",
        "    elif activation == \"sigmoid\":\n",
        "        activation_fn = torch.nn.Sigmoid()\n",
        "    elif activation == \"softmax2d\":\n",
        "        activation_fn = torch.nn.Softmax2d()\n",
        "    else:\n",
        "        raise NotImplementedError(\"Activation must be 'sigmoid' or 'softmax2d'.\")\n",
        "\n",
        "    # Your code here...\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Dice Loss for segmentation tasks.\"\"\"\n",
        "    __name__ = 'dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        # Your code here...\n",
        "\n",
        "\n",
        "class BCEDiceLoss(DiceLoss):\n",
        "    \"\"\"Combination of BCE Loss and Dice Loss.\"\"\"\n",
        "    __name__ = 'bce_dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid', lambda_dice=1.0, lambda_bce=1.0):\n",
        "        super().__init__(eps, activation)\n",
        "        self.lambda_dice = lambda_dice\n",
        "        self.lambda_bce = lambda_bce\n",
        "\n",
        "        if activation is None:\n",
        "            self.bce = nn.BCELoss(reduction='mean')\n",
        "        else:\n",
        "            self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        # Your code here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrLRswvhTFNL"
      },
      "source": [
        "# Task 2: To see the effect of data augmentation, we will do ablation. Let's train the model without the data augmentation.\n",
        "\n",
        "By not passing the `augmentation` parameter when initializing the `LandCoverDataset`, you can create a data loader that does not contain the augmented image data. However, in this notebook (for educational purpose), just to resize the image, we created a separate function (`get_training_no_augmentation()`). Passing an image without resizing it will cause memory error as the image size is bigger than the Colab's GPU capacity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWoMas6WKL8n"
      },
      "source": [
        "## 2.1 Dataset and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KArxixSgTI6i"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances\n",
        "train_dataset_without_aug = LandCoverDataset(train_df,augmentation=get_training_no_augmentation(),\n",
        "                                                  preprocessing=get_preprocessing(preprocessing_fn),\n",
        "                                                   class_rgb_values=select_class_rgb_values)\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# Create test dataset instance\n",
        "test_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# Create dataloaders for train, val and test datasets\n",
        "train_loader = DataLoader(train_dataset_without_aug, batch_size=4, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ckT3WhAJXtD"
      },
      "source": [
        "Visualise test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "KFoC0N0dqUSr",
        "outputId": "99a7a52a-5da3-4e2a-8428-aef457cbc0f2"
      },
      "outputs": [],
      "source": [
        "# test dataset for visualization (without preprocessing augmentations & transformations)\n",
        "test_dataset_vis = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# get a random test image/mask index\n",
        "random_idx = random.randint(0, len(test_dataset_vis)-1)\n",
        "image, mask = test_dataset_vis[random_idx]\n",
        "\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLuT8KsLJgiV"
      },
      "source": [
        "## 2.2 Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXW6AI4zThcs"
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed.\n",
        "TRAINING = True\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 1\n",
        "\n",
        "# Set device: `cuda` for GPU or `cpu` for CPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define loss function used during training\n",
        "# Set your loss function here... \n",
        "loss = None\n",
        "\n",
        "# Define evaluation metrics\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "\n",
        "# Define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n",
        "\n",
        "# # load best saved model checkpoint from previous commit (if present)\n",
        "# if os.path.exists('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth'):\n",
        "#     model = torch.load('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth', map_location=DEVICE)\n",
        "#     print('Loaded pre-trained DeepLabV3+ model!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBSs5ErLKmsF"
      },
      "source": [
        "Setup training process for one epoch using Pytorch helper class `smp.utils.train.TrainEpoch`.\n",
        "\n",
        "This helps handle the forward pass, loss calculation, backpropagation, and weight updates for each batch of images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n90G1-alTp8z"
      },
      "outputs": [],
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-_b9gYkLEQt"
      },
      "source": [
        "## 2.3 Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mfc_Pxf2TmwY"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**: you can train your own model, but this will take some time. Instead, you can use one of the pre-trained models provided which have been trained over 30 epochs. \n",
        "\n",
        "> Skip to section 2.4 to load a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwvavB1rTyjT",
        "outputId": "50b3c7ce-f6b0-45d8-cd12-30f9fc8da322"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            torch.save(model, './no_aug_30_epochs.pth')\n",
        "            print('Model saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNU-682jL5uc"
      },
      "source": [
        "## 2.4 Evaluate your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Hint**: load a pre-trained model for better results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt5xYeOCavhe"
      },
      "outputs": [],
      "source": [
        "# load best model (or pretrained model)\n",
        "if os.path.exists('/content/no_aug_30_epochs.pth'):\n",
        "    best_model = torch.load('/content/no_aug_30_epochs.pth', weights_only=False, map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "WK8cvvRuT-BR",
        "outputId": "0a456451-346a-4b09-b040-b40d427f89f2"
      },
      "outputs": [],
      "source": [
        "test_epoch = smp.utils.train.ValidEpoch(\n",
        "    best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lhdoQ0MTWLcl"
      },
      "outputs": [],
      "source": [
        "sample_preds_folder = 'sample_predictions/'\n",
        "if not os.path.exists(sample_preds_folder):\n",
        "    os.makedirs(sample_preds_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFe8ZdG6WL6b"
      },
      "source": [
        "Visualise the predictions output on some of the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6UKYQm2WNSh"
      },
      "outputs": [],
      "source": [
        "for idx in range(7):\n",
        "\n",
        "    image, gt_mask = test_dataset[idx]\n",
        "    image_vis = test_dataset_vis[idx][0].astype('uint8')\n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "    # Predict test image\n",
        "    pred_mask = best_model(x_tensor)\n",
        "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "\n",
        "    # Convert pred_mask from `CHW` format to `HWC` format\n",
        "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "\n",
        "    # Get prediction channel corresponding to foreground\n",
        "    pred_urban_land_heatmap = pred_mask[:,:,select_classes.index('urban_land')]\n",
        "    pred_mask = colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values)\n",
        "\n",
        "    # Convert gt_mask from `CHW` format to `HWC` format\n",
        "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
        "    gt_mask = colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values)\n",
        "    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n",
        "\n",
        "    visualize(\n",
        "        original_image = image_vis,\n",
        "        ground_truth_mask = gt_mask,\n",
        "        predicted_mask = pred_mask,\n",
        "        pred_urban_land_heatmap = pred_urban_land_heatmap\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Task**: write functions to compute evaluation metrics (IoU, DICE) in each class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jfU7DC9eLXu"
      },
      "outputs": [],
      "source": [
        "# per class metrics\n",
        "     \n",
        "\n",
        "def evaluate_per_class_metrics(model, dataloader, device, class_names):\n",
        "    \"\"\"\n",
        "    Compute the average Dice Score and IoU per class for the best model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained segmentation model.\n",
        "        dataloader (torch.utils.data.DataLoader): Dataloader for test data.\n",
        "        device (torch.device): Device (CPU or CUDA).\n",
        "        class_names (list): List of class names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing per-class Dice Score and IoU.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # dict to store per-class dice scores \n",
        "    dice_scores = {cls: [] for cls in class_names}\n",
        "\n",
        "    # dict to store per-class iou\n",
        "    iou_scores = {cls: [] for cls in class_names}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            preds = model(images)\n",
        "            preds = torch.sigmoid(preds)  # Ensure values are between 0 and 1\n",
        "            preds = (preds > 0.3).float()  # Binarize predictions\n",
        "            # Compute Dice Score & IoU per class\n",
        "            for i, cls in enumerate(class_names):\n",
        "                dice = f_score(preds[:, i], masks[:, i], beta=1).item()\n",
        "                iou = None # Write a function to implement this..\n",
        "\n",
        "                dice_scores[cls].append(dice)\n",
        "                iou_scores[cls].append(iou)\n",
        "\n",
        "    # Compute mean Dice Score & IoU per class\n",
        "    avg_dice = {cls: np.mean(scores) for cls, scores in dice_scores.items()}\n",
        "    avg_iou = {cls: np.mean(scores) for cls, scores in iou_scores.items()}\n",
        "\n",
        "    # Create DataFrame\n",
        "    df_metrics = pd.DataFrame({\n",
        "        \"Class\": class_names,\n",
        "        \"Avg Dice Score\": [avg_dice[cls] for cls in class_names],\n",
        "        \"Avg IoU Score\": [avg_iou[cls] for cls in class_names]\n",
        "    })\n",
        "\n",
        "    return df_metrics\n",
        "\n",
        "\n",
        "# Run the evaluation\n",
        "# Your code here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd4Xa46wSkvG"
      },
      "source": [
        "# Task 3: Train the model with the data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKveJfkQjC1i"
      },
      "source": [
        "## 3.1 Dataset and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MxTWxR33qiZQ"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances with augmented data\n",
        "train_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCq7pXdmjo1g"
      },
      "source": [
        "## 3.2 Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:17.806622Z",
          "iopub.status.busy": "2020-11-11T04:20:17.805771Z",
          "iopub.status.idle": "2020-11-11T04:20:21.985521Z",
          "shell.execute_reply": "2020-11-11T04:20:21.986028Z"
        },
        "id": "OnVwfVknQIt1",
        "papermill": {
          "duration": 4.6083,
          "end_time": "2020-11-11T04:20:21.986189",
          "exception": false,
          "start_time": "2020-11-11T04:20:17.377889",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = True\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 1\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "# loss = smp.utils.losses.DiceLoss()\n",
        "loss = DiceLoss()\n",
        "\n",
        "# loss = BCEDiceLoss()\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:22.099274Z",
          "iopub.status.busy": "2020-11-11T04:20:22.098455Z",
          "iopub.status.idle": "2020-11-11T04:20:22.121316Z",
          "shell.execute_reply": "2020-11-11T04:20:22.120427Z"
        },
        "id": "uO7_OACaQIt1",
        "papermill": {
          "duration": 0.082187,
          "end_time": "2020-11-11T04:20:22.121494",
          "exception": false,
          "start_time": "2020-11-11T04:20:22.039307",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iknaFwFojt8R"
      },
      "source": [
        "## 3.3 Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6-u_RqwkdZrL"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**: once again, the training setup is shown, but you can use one of the pre-trained models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:22.346852Z",
          "iopub.status.busy": "2020-11-11T04:20:22.345942Z",
          "iopub.status.idle": "2020-11-11T05:54:51.737107Z",
          "shell.execute_reply": "2020-11-11T05:54:51.736560Z"
        },
        "id": "IutdGndaQIt2",
        "papermill": {
          "duration": 5669.449912,
          "end_time": "2020-11-11T05:54:51.737233",
          "exception": false,
          "start_time": "2020-11-11T04:20:22.287321",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            torch.save(model, '/content/aug_30_epochs.pth')\n",
        "            print('Model saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXQDtyWQjxEm"
      },
      "source": [
        "## 3.4 Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T05:54:55.915262Z",
          "iopub.status.busy": "2020-11-11T05:54:55.914377Z",
          "iopub.status.idle": "2020-11-11T05:54:56.035770Z",
          "shell.execute_reply": "2020-11-11T05:54:56.036521Z"
        },
        "id": "acA_0-BwQIt2",
        "papermill": {
          "duration": 1.141206,
          "end_time": "2020-11-11T05:54:56.036700",
          "exception": false,
          "start_time": "2020-11-11T05:54:54.895494",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Unet model from this run.\n"
          ]
        }
      ],
      "source": [
        "# load best saved model checkpoint from the current run\n",
        "if os.path.exists('/content/aug_30_epochs.pth'):\n",
        "    best_model = torch.load('/content/aug_30_epochs.pth', weights_only=False, map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir2XvVrd_aRE"
      },
      "source": [
        "Visualise the predictions output on some of the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T05:55:06.975351Z",
          "iopub.status.busy": "2020-11-11T05:55:06.974233Z",
          "iopub.status.idle": "2020-11-11T06:00:23.885708Z",
          "shell.execute_reply": "2020-11-11T06:00:23.884781Z"
        },
        "id": "QVvVZ9ccQIt4",
        "papermill": {
          "duration": 318.110868,
          "end_time": "2020-11-11T06:00:23.885824",
          "exception": false,
          "start_time": "2020-11-11T05:55:05.774956",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "for idx in range(7):\n",
        "\n",
        "    image, gt_mask = test_dataset[idx]\n",
        "    image_vis = test_dataset_vis[idx][0].astype('uint8')\n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "    # Predict test image\n",
        "    pred_mask = best_model(x_tensor)\n",
        "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "\n",
        "    # Convert pred_mask from `CHW` format to `HWC` format\n",
        "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "\n",
        "    # Get prediction channel corresponding to foreground\n",
        "    pred_urban_land_heatmap = pred_mask[:,:,select_classes.index('urban_land')]\n",
        "    pred_mask = colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values)\n",
        "    \n",
        "    # Convert gt_mask from `CHW` format to `HWC` format\n",
        "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
        "    gt_mask = colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values)\n",
        "    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n",
        "\n",
        "    visualize(\n",
        "        original_image = image_vis,\n",
        "        ground_truth_mask = gt_mask,\n",
        "        predicted_mask = pred_mask,\n",
        "        pred_urban_land_heatmap = pred_urban_land_heatmap\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T06:00:29.779356Z",
          "iopub.status.busy": "2020-11-11T06:00:29.778414Z",
          "iopub.status.idle": "2020-11-11T06:02:40.900735Z",
          "shell.execute_reply": "2020-11-11T06:02:40.897939Z"
        },
        "id": "FICx4seLQIt5",
        "papermill": {
          "duration": 132.588372,
          "end_time": "2020-11-11T06:02:40.900910",
          "exception": false,
          "start_time": "2020-11-11T06:00:28.312538",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_epoch = smp.utils.train.ValidEpoch(\n",
        "    best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect per-class metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ7bRTP6fUb-"
      },
      "outputs": [],
      "source": [
        "# Your code here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, compare results with and without augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTATaD7IfZt7"
      },
      "outputs": [],
      "source": [
        "# compare with augmentation to without augmentation:\n",
        "# Merge results into a single DataFrame for better comparison\n",
        "df_comparison = pd.merge(df_results_no_aug, df_results_aug, on=\"Class\", suffixes=(\"_No_Aug\", \"_Aug\"))\n",
        "\n",
        "# Rename columns for clarity\n",
        "df_comparison.rename(columns={\n",
        "    \"Avg Dice Score_No_Aug\": \"Dice Score (No Aug)\",\n",
        "    \"Avg Dice Score_Aug\": \"Dice Score (Aug)\",\n",
        "    \"Avg IoU Score_No_Aug\": \"IoU Score (No Aug)\",\n",
        "    \"Avg IoU Score_Aug\": \"IoU Score (Aug)\"\n",
        "}, inplace=True)\n",
        "\n",
        "df_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZDOec7ZOxGX"
      },
      "source": [
        "# Task 4: Loss comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyOzaq-6tnyB"
      },
      "source": [
        "### Now, let's try with different loss function: Dice Loss vs BCE Loss.\n",
        "\n",
        "You can try implementing or importing different loss functions from pytorch library.  \n",
        "Also, here's a survey for loss functions used for image segmentation: https://arxiv.org/pdf/2006.14822.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umoWmCNIj9r-"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances with augmented data\n",
        "train_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HiKxTtMOze-"
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = True\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 1\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "loss = None\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MBHg_qIO9b5"
      },
      "outputs": [],
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0UrZHjiPBON"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G75L-7HqPFDG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            torch.save(model, './bceloss_30_epochs.pth')\n",
        "            print('Model saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Hint**: use a pre-trained model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqI_Ig5Nicr6"
      },
      "outputs": [],
      "source": [
        "if os.path.exists('./bceloss_30_epochs.pth'):\n",
        "    best_model = torch.load('./bceloss_30_epochs.pth', weights_only=False, map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yykVXiHKPyFu"
      },
      "outputs": [],
      "source": [
        "test_epoch = smp.utils.train.ValidEpoch(\n",
        "    best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['bce_dice_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Same as before, evaluate per-class metrics..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb6cWOL7i5xB"
      },
      "outputs": [],
      "source": [
        "# Your code here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, compare the results from the two different loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEuQ7TPBTE0u"
      },
      "outputs": [],
      "source": [
        "# compare with dice to bce:\n",
        "# Merge results into a single DataFrame for better comparison\n",
        "df_comparison = pd.merge(df_results_aug, df_results_bce, on=\"Class\", suffixes=(\"_Dice\", \"_BCE\"))\n",
        "\n",
        "# Rename columns for clarity\n",
        "df_comparison.rename(columns={\n",
        "    \"Avg Dice Score_Dice\": \"Dice Score (Dice)\",\n",
        "    \"Avg Dice Score_BCE\": \"Dice Score (BCE)\",\n",
        "    \"Avg IoU Score_Dice\": \"IoU Score (Dice)\",\n",
        "    \"Avg IoU Score_BCE\": \"IoU Score (BCE)\"\n",
        "}, inplace=True)\n",
        "\n",
        "df_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62UgBVoulNM"
      },
      "source": [
        "**Discussion**  \n",
        "We have trained the same model with two different losses: Diceloss and BCEloss.\n",
        "\n",
        "What difference do you see from the IOU score?   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I216sWjnh0Mo"
      },
      "source": [
        "# Task 5: compute the average area difference between actual and predicted classes\n",
        "\n",
        "\n",
        "Hint: base area on pixel.\n",
        "https://stackoverflow.com/questions/58068315/calculate-the-area-of-the-masks-in-pixels-in-grey-scale-images-with-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question**: What is the error of your predictions in terms of water area/surface?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CICJ73mfl6p3"
      },
      "outputs": [],
      "source": [
        "def compute_average_area_difference(model, dataloader, device, class_names):\n",
        "    \"\"\"\n",
        "    Compute the average area difference (per class) between predicted and ground truth masks.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Trained segmentation model.\n",
        "        dataloader (torch.utils.data.DataLoader): Test dataloader.\n",
        "        device (torch.device): CPU or GPU.\n",
        "        class_names (list): List of class names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Table containing average area difference per class.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize dictionary to store sum of differences\n",
        "    total_area_diffs = {cls: 0 for cls in class_names}\n",
        "    num_test_images = len(dataloader.dataset)  # Get total test images\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.cpu().numpy()  # Move ground truth masks to CPU\n",
        "            masks = (masks > 0).astype(np.uint8)  # Ensure binary ground truth masks\n",
        "\n",
        "            # Get predictions\n",
        "            preds = model(images)\n",
        "            preds = torch.sigmoid(preds)  # Convert logits to probabilities\n",
        "            preds = (preds > 0.5).float().cpu().numpy()  # Convert to binary masks\n",
        "\n",
        "            # Loop over batch\n",
        "            batch_size = images.shape[0]\n",
        "            for b in range(batch_size):\n",
        "                # Iterate through each class\n",
        "                for i, cls in enumerate(class_names):\n",
        "                    # Extract single-channel binary masks for the class\n",
        "                    pred_mask = preds[b, i].astype(np.uint8)  # Predicted class mask\n",
        "                    gt_mask = masks[b, i].astype(np.uint8)  # GT class mask\n",
        "\n",
        "                    # Compute absolute difference in area\n",
        "                    \n",
        "                    # Your code here... \n",
        "\n",
        "    # Compute mean area difference per class (normalize by number of images)\n",
        "    avg_area_diff = {cls: total_area_diffs[cls] / num_test_images for cls in class_names}\n",
        "\n",
        "    # Create a DataFrame for visualization\n",
        "    df_area_difference = pd.DataFrame({\n",
        "        \"Class\": class_names,\n",
        "        \"Avg Area Difference (Pixels)\": [avg_area_diff[cls] for cls in class_names]\n",
        "    })\n",
        "\n",
        "    return df_area_difference\n",
        "\n",
        "# Run the function to compute area differences\n",
        "df_area_diff = compute_average_area_difference(best_model, test_dataloader, DEVICE, select_classes)\n",
        "\n",
        "df_area_diff"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "papermill": {
      "duration": 6201.325856,
      "end_time": "2020-11-11T06:02:57.609445",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-11-11T04:19:36.283589",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
